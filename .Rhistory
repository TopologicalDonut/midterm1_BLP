# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score)) %>%
select(-min_caffeine_score)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
write_csv(w_data_long, "simulated_data/merger_w_data.csv")
View(final_data)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score)) %>%
select(-product, -min_caffeine_score)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- final_data %>%
select(-product, -min_caffeine_score)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data %>% select(-product, -min_caffeine_score)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data %>% select(-c('product', 'min_caffeine_score'))
View(w_data_long)
View(final_data)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- subset(final_data, select = -c("product", "min_caffeine_score"))
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- select(final_data,-product)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- select(final_data,-"product")
View(w_data)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data %>% select(-product,-min_caffeine_score)
View(final_data)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data %>% dplyr::select(-product,-min_caffeine_score)
write_csv(w_data_long, "simulated_data/merger_w_data.csv")
View(final_data)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data %>% dplyr::select(-product,-min_caffeine_score)
write_csv(final_data, "simulated_data/merger_w_data.csv")
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data %>% dplyr::select(final_data, -product, -min_caffeine_score)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(min_caffeine_score = min(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(min_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(min_caffeine_score), min_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- final_data %>%
dplyr::select(-product, -min_caffeine_score)
write_csv(final_data, "simulated_data/merger_w_data.csv")
View(final_data)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
min_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(avg_caffeine_score = mean(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(avg_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(avg_caffeine_score), avg_caffeine_score, caffeine_score))
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
avg_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(avg_caffeine_score = mean(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(avg_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(avg_caffeine_score), avg_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- final_data %>%
dplyr::select(-product, -avg_caffeine_score)
write_csv(final_data, "simulated_data/merger_w_data2.csv")
View(avg_caffeine_scores)
View(final_data)
View(min_caffeine_scores)
View(avg_caffeine_scores)
View(min_caffeine_scores)
View(final_data)
library(MASS)
# Parameters
num_markets = 200
num_individuals = 500
num_variables = 2
# Mean vector and covariance matrix for the multivariate normal distribution
mean_vector = rep(0, num_variables)
cov_matrix = diag(num_variables)  # Identity matrix for simplicity
# Generate the random draws for all individuals in all markets
# Each row represents a draw for an individual in a market
random_draws = mvrnorm(n = num_markets * num_individuals, mu = mean_vector, Sigma = cov_matrix)
# Convert the matrix to a data frame
draws_df = data.frame(random_draws)
# Save the draws to a CSV file
output_filename = sprintf("simulated_data/%ddraws.csv", num_individuals)
write.table(draws_df, output_filename, sep=",", row.names = FALSE, col.names = FALSE)
library(MASS)
# Parameters
num_markets = 200
num_individuals = 50
num_variables = 2
# Mean vector and covariance matrix for the multivariate normal distribution
mean_vector = rep(0, num_variables)
cov_matrix = diag(num_variables)  # Identity matrix for simplicity
# Generate the random draws for all individuals in all markets
# Each row represents a draw for an individual in a market
random_draws = mvrnorm(n = num_markets * num_individuals, mu = mean_vector, Sigma = cov_matrix)
# Convert the matrix to a data frame
draws_df = data.frame(random_draws)
# Save the draws to a CSV file
output_filename = sprintf("simulated_data/%ddraws.csv", num_individuals)
write.table(draws_df, output_filename, sep=",", row.names = FALSE, col.names = FALSE)
library(MASS)
# Parameters
num_markets = 200
num_individuals = 50
num_variables = 2
# Mean vector and covariance matrix for the multivariate normal distribution
mean_vector = rep(0, num_variables)
cov_matrix = diag(num_variables)  # Identity matrix for simplicity
# Generate the random draws for all individuals in all markets
# Each row represents a draw for an individual in a market
random_draws = mvrnorm(n = num_markets * num_individuals, mu = mean_vector, Sigma = cov_matrix)
# Convert the matrix to a data frame
draws_df = data.frame(random_draws)
# Save the draws to a CSV file
output_filename = sprintf("simulated_data/%ddraws.csv", num_individuals)
write.table(draws_df, output_filename, sep=",", row.names = FALSE, col.names = FALSE)
library(MASS)
# Parameters
num_markets = 200
num_individuals = 500
num_variables = 2
# Mean vector and covariance matrix for the multivariate normal distribution
mean_vector = rep(0, num_variables)
cov_matrix = diag(num_variables)  # Identity matrix for simplicity
# Generate the random draws for all individuals in all markets
# Each row represents a draw for an individual in a market
random_draws = mvrnorm(n = num_markets * num_individuals, mu = mean_vector, Sigma = cov_matrix)
# Convert the matrix to a data frame
draws_df = data.frame(random_draws)
# Save the draws to a CSV file
output_filename = sprintf("simulated_data/%ddraws.csv", num_individuals)
write.table(draws_df, output_filename, sep=",", row.names = FALSE, col.names = FALSE)
library(MASS)
# Parameters
num_markets = 200
num_individuals = 50
num_variables = 2
set.seed(98426)
# Mean vector and covariance matrix for the multivariate normal distribution
mean_vector = rep(0, num_variables)
cov_matrix = diag(num_variables)  # Identity matrix for simplicity
# Generate the random draws for all individuals in all markets
# Each row represents a draw for an individual in a market
random_draws = mvrnorm(n = num_markets * num_individuals, mu = mean_vector, Sigma = cov_matrix)
# Convert the matrix to a data frame
draws_df = data.frame(random_draws)
# Save the draws to a CSV file
output_filename = sprintf("simulated_data/%ddraws.csv", num_individuals)
write.table(draws_df, output_filename, sep=",", row.names = FALSE, col.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(readr)
w_data <- read_csv("simulated_data/midterm_simulated_market_data_w.csv")
# Pivot to long format and create a unique identifier
w_data_long <- w_data %>%
pivot_longer(cols = starts_with("caffeine_score"),
names_to = c(".value", "product"),
names_pattern = "^(.+)_(.+)$") %>%
mutate(product_id = row_number())  # Unique identifier for each product
# Map MD and TH to the same firm ID but keep their products distinct
firm_ids <- c("MD" = 1, "TH" = 1, "SB" = 2)
w_data_long <- w_data_long %>%
mutate(firm = firm_ids[product])
# For MD and TH, calculate the minimum caffeine score and then merge this information back
avg_caffeine_scores <- w_data_long %>%
filter(firm == 1) %>%
group_by(marketid) %>%
summarise(avg_caffeine_score = mean(caffeine_score, na.rm = TRUE), .groups = 'drop')
# Join the minimum caffeine score with the original data and adjust for MD and TH
final_data <- w_data_long %>%
left_join(avg_caffeine_scores, by = "marketid") %>%
mutate(caffeine_score = if_else(firm == 1 & !is.na(avg_caffeine_score), avg_caffeine_score, caffeine_score))
# Removing unneeded columns
final_data <- final_data %>%
dplyr::select(-product, -avg_caffeine_score)
write_csv(final_data, "simulated_data/merger_w_data2.csv")
View(w_data_long)
View(w_data_long)
